save path : ./snapshots/uniform_6_quantized_cifar10_rnqresnet20_100
{'aq_bits': 6, 'aq_type': 'uniform', 'arch': 'rnqresnet20', 'batch_size': 128, 'data_path': '../../datasets/CIFAR10/cifar', 'dataset': 'cifar10', 'decay': 0.0001, 'epochs': 100, 'evaluate': False, 'gammas': [0.1, 0.1, 0.1], 'learning_rate': 0.01, 'manualSeed': 6742, 'momentum': 0.9, 'ngpu': 4, 'pretrained': '', 'print_freq': 200, 'resume': 'snapshots/finetune_cifar10_resnet20_300/model_best.pth.tar', 'save_path': './snapshots/uniform_6_quantized_cifar10_rnqresnet20_100', 'schedule': [30, 60, 90], 'start_epoch': 0, 'use_cuda': True, 'workers': 16}
Random Seed: 6742
python version : 3.7.3 (default, Mar 27 2019, 22:11:17)  [GCC 7.3.0]
torch  version : 1.1.0
cudnn  version : 7501
=> creating model 'rnqresnet20'
=> network :
 CifarResNet(
  (conv_1_3x3): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (stage_1): Sequential(
    (0): ResNetBasicblock(
      (conv_a): RNQConv2d(
        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=16, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): RNQConv2d(
        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=16, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ResNetBasicblock(
      (conv_a): RNQConv2d(
        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=16, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): RNQConv2d(
        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=16, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): RNQConv2d(
        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=16, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_a): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): RNQConv2d(
        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=16, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_b): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_2): Sequential(
    (0): ResNetBasicblock(
      (conv_a): RNQConv2d(
        16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=16, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): RNQConv2d(
        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=32, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): RNQConv2d(
        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=32, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): RNQConv2d(
        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=32, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): RNQConv2d(
        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=32, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_a): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): RNQConv2d(
        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=32, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_b): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (stage_3): Sequential(
    (0): ResNetBasicblock(
      (conv_a): RNQConv2d(
        32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=32, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): RNQConv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=64, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): DownsampleA(
        (avg): AvgPool2d(kernel_size=1, stride=2, padding=0)
      )
    )
    (1): ResNetBasicblock(
      (conv_a): RNQConv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=64, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): RNQConv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=64, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ResNetBasicblock(
      (conv_a): RNQConv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=64, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_b): RNQConv2d(
        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (routing): Sequential(
          (0): Linear(in_features=64, out_features=16, bias=True)
          (1): ReLU()
          (2): Linear(in_features=16, out_features=1, bias=True)
          (3): Sigmoid()
        )
      )
      (bn_b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
  (classifier): QuantLinear(in_features=64, out_features=10, bias=True, method=KMeans, nbits=4)
)
=> loading checkpoint 'snapshots/finetune_cifar10_resnet20_300/model_best.pth.tar'
=> loaded checkpoint 'snapshots/finetune_cifar10_resnet20_300/model_best.pth.tar' (epoch 291)

==>>[2019-08-30 20:38:34] [Epoch=000/100] [Need: 00:00:00] [learning_rate=0.0100] [Best : Accuracy=0.00, Error=100.00]
  Epoch: [000][000/391]   Time 35.886 (35.886)   Data 1.218 (1.218)   Loss 0.1368 (0.1368)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-08-30 20:39:10]
  Epoch: [000][200/391]   Time 0.283 (0.490)   Data 0.000 (0.006)   Loss 0.1622 (0.1729)   Prec@1 95.312 (93.804)   Prec@5 100.000 (99.938)   [2019-08-30 20:40:12]
  **Test** Prec@1 86.830 Prec@5 99.520 Error@1 13.170

==>>[2019-08-30 20:41:32] [Epoch=001/100] [Need: 04:52:56] [learning_rate=0.0100] [Best : Accuracy=86.83, Error=13.17]
  Epoch: [001][000/391]   Time 2.923 (2.923)   Data 2.535 (2.535)   Loss 0.1736 (0.1736)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-08-30 20:41:35]
  Epoch: [001][200/391]   Time 0.229 (0.329)   Data 0.000 (0.013)   Loss 0.1446 (0.1567)   Prec@1 92.969 (94.516)   Prec@5 100.000 (99.934)   [2019-08-30 20:42:38]
  **Test** Prec@1 86.830 Prec@5 99.510 Error@1 13.170

==>>[2019-08-30 20:44:05] [Epoch=002/100] [Need: 04:30:02] [learning_rate=0.0100] [Best : Accuracy=86.83, Error=13.17]
  Epoch: [002][000/391]   Time 3.386 (3.386)   Data 3.069 (3.069)   Loss 0.2032 (0.2032)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-08-30 20:44:08]
  Epoch: [002][200/391]   Time 0.291 (0.355)   Data 0.000 (0.016)   Loss 0.1648 (0.1621)   Prec@1 93.750 (94.135)   Prec@5 100.000 (99.907)   [2019-08-30 20:45:16]
  **Test** Prec@1 87.570 Prec@5 99.520 Error@1 12.430

==>>[2019-08-30 20:46:42] [Epoch=003/100] [Need: 04:22:29] [learning_rate=0.0100] [Best : Accuracy=87.57, Error=12.43]
  Epoch: [003][000/391]   Time 4.653 (4.653)   Data 4.215 (4.215)   Loss 0.1310 (0.1310)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-08-30 20:46:47]
  Epoch: [003][200/391]   Time 0.435 (0.365)   Data 0.000 (0.021)   Loss 0.1125 (0.1551)   Prec@1 96.875 (94.407)   Prec@5 100.000 (99.973)   [2019-08-30 20:47:55]
  **Test** Prec@1 88.550 Prec@5 99.550 Error@1 11.450

==>>[2019-08-30 20:49:20] [Epoch=004/100] [Need: 04:17:57] [learning_rate=0.0100] [Best : Accuracy=88.55, Error=11.45]
  Epoch: [004][000/391]   Time 3.702 (3.702)   Data 3.316 (3.316)   Loss 0.1397 (0.1397)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-08-30 20:49:24]
  Epoch: [004][200/391]   Time 0.309 (0.358)   Data 0.000 (0.017)   Loss 0.2384 (0.1637)   Prec@1 92.188 (94.166)   Prec@5 100.000 (99.957)   [2019-08-30 20:50:32]
  **Test** Prec@1 88.330 Prec@5 99.650 Error@1 11.670

==>>[2019-08-30 20:52:02] [Epoch=005/100] [Need: 04:15:39] [learning_rate=0.0100] [Best : Accuracy=88.55, Error=11.45]
  Epoch: [005][000/391]   Time 4.272 (4.272)   Data 3.701 (3.701)   Loss 0.1318 (0.1318)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-30 20:52:06]
  Epoch: [005][200/391]   Time 0.412 (0.398)   Data 0.000 (0.019)   Loss 0.1303 (0.1590)   Prec@1 96.094 (94.282)   Prec@5 100.000 (99.918)   [2019-08-30 20:53:22]
  **Test** Prec@1 88.000 Prec@5 99.260 Error@1 12.000

==>>[2019-08-30 20:54:58] [Epoch=006/100] [Need: 04:16:32] [learning_rate=0.0100] [Best : Accuracy=88.55, Error=11.45]
  Epoch: [006][000/391]   Time 2.972 (2.972)   Data 2.542 (2.542)   Loss 0.1381 (0.1381)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-08-30 20:55:01]
  Epoch: [006][200/391]   Time 0.607 (0.387)   Data 0.000 (0.013)   Loss 0.1229 (0.1541)   Prec@1 95.312 (94.601)   Prec@5 100.000 (99.942)   [2019-08-30 20:56:16]
  **Test** Prec@1 88.370 Prec@5 99.630 Error@1 11.630

==>>[2019-08-30 20:57:50] [Epoch=007/100] [Need: 04:15:46] [learning_rate=0.0100] [Best : Accuracy=88.55, Error=11.45]
  Epoch: [007][000/391]   Time 2.937 (2.937)   Data 2.290 (2.290)   Loss 0.0830 (0.0830)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-08-30 20:57:53]
  Epoch: [007][200/391]   Time 0.296 (0.374)   Data 0.000 (0.012)   Loss 0.2711 (0.1574)   Prec@1 89.844 (94.282)   Prec@5 99.219 (99.934)   [2019-08-30 20:59:05]
  **Test** Prec@1 88.950 Prec@5 99.640 Error@1 11.050

==>>[2019-08-30 21:00:39] [Epoch=008/100] [Need: 04:13:48] [learning_rate=0.0100] [Best : Accuracy=88.95, Error=11.05]
  Epoch: [008][000/391]   Time 4.787 (4.787)   Data 4.261 (4.261)   Loss 0.1865 (0.1865)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-08-30 21:00:44]
  Epoch: [008][200/391]   Time 0.362 (0.394)   Data 0.000 (0.022)   Loss 0.1565 (0.1550)   Prec@1 94.531 (94.438)   Prec@5 100.000 (99.930)   [2019-08-30 21:01:59]
  **Test** Prec@1 88.100 Prec@5 99.570 Error@1 11.900

==>>[2019-08-30 21:03:31] [Epoch=009/100] [Need: 04:12:07] [learning_rate=0.0100] [Best : Accuracy=88.95, Error=11.05]
  Epoch: [009][000/391]   Time 4.290 (4.290)   Data 3.841 (3.841)   Loss 0.0974 (0.0974)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-08-30 21:03:35]
  Epoch: [009][200/391]   Time 0.299 (0.377)   Data 0.000 (0.019)   Loss 0.1515 (0.1492)   Prec@1 92.969 (94.873)   Prec@5 100.000 (99.953)   [2019-08-30 21:04:47]
  **Test** Prec@1 88.360 Prec@5 99.620 Error@1 11.640

==>>[2019-08-30 21:06:19] [Epoch=010/100] [Need: 04:09:38] [learning_rate=0.0100] [Best : Accuracy=88.95, Error=11.05]
  Epoch: [010][000/391]   Time 4.214 (4.214)   Data 3.784 (3.784)   Loss 0.1468 (0.1468)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-08-30 21:06:23]
  Epoch: [010][200/391]   Time 0.353 (0.387)   Data 0.000 (0.019)   Loss 0.2239 (0.1537)   Prec@1 92.969 (94.496)   Prec@5 100.000 (99.930)   [2019-08-30 21:07:37]
  **Test** Prec@1 88.760 Prec@5 99.690 Error@1 11.240

==>>[2019-08-30 21:09:10] [Epoch=011/100] [Need: 04:07:27] [learning_rate=0.0100] [Best : Accuracy=88.95, Error=11.05]
  Epoch: [011][000/391]   Time 4.745 (4.745)   Data 4.061 (4.061)   Loss 0.1278 (0.1278)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-08-30 21:09:15]
  Epoch: [011][200/391]   Time 0.305 (0.407)   Data 0.000 (0.020)   Loss 0.1204 (0.1516)   Prec@1 97.656 (94.663)   Prec@5 100.000 (99.946)   [2019-08-30 21:10:32]
  **Test** Prec@1 87.630 Prec@5 99.590 Error@1 12.370

==>>[2019-08-30 21:12:02] [Epoch=012/100] [Need: 04:05:22] [learning_rate=0.0100] [Best : Accuracy=88.95, Error=11.05]
  Epoch: [012][000/391]   Time 3.524 (3.524)   Data 3.050 (3.050)   Loss 0.2198 (0.2198)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-08-30 21:12:06]
  Epoch: [012][200/391]   Time 0.335 (0.381)   Data 0.000 (0.015)   Loss 0.1298 (0.1505)   Prec@1 96.094 (94.706)   Prec@5 100.000 (99.922)   [2019-08-30 21:13:19]
  **Test** Prec@1 86.150 Prec@5 99.410 Error@1 13.850

==>>[2019-08-30 21:14:54] [Epoch=013/100] [Need: 04:03:03] [learning_rate=0.0100] [Best : Accuracy=88.95, Error=11.05]
  Epoch: [013][000/391]   Time 3.948 (3.948)   Data 3.420 (3.420)   Loss 0.1186 (0.1186)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-30 21:14:58]
  Epoch: [013][200/391]   Time 0.490 (0.385)   Data 0.000 (0.017)   Loss 0.1423 (0.1566)   Prec@1 95.312 (94.516)   Prec@5 100.000 (99.938)   [2019-08-30 21:16:12]
  **Test** Prec@1 86.250 Prec@5 99.220 Error@1 13.750

==>>[2019-08-30 21:17:43] [Epoch=014/100] [Need: 04:00:27] [learning_rate=0.0100] [Best : Accuracy=88.95, Error=11.05]
  Epoch: [014][000/391]   Time 3.797 (3.797)   Data 3.461 (3.461)   Loss 0.0979 (0.0979)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-30 21:17:47]
  Epoch: [014][200/391]   Time 0.538 (0.388)   Data 0.003 (0.017)   Loss 0.1286 (0.1626)   Prec@1 94.531 (94.158)   Prec@5 100.000 (99.926)   [2019-08-30 21:19:01]
  **Test** Prec@1 87.790 Prec@5 99.500 Error@1 12.210

==>>[2019-08-30 21:20:32] [Epoch=015/100] [Need: 03:57:40] [learning_rate=0.0100] [Best : Accuracy=88.95, Error=11.05]
  Epoch: [015][000/391]   Time 4.325 (4.325)   Data 3.857 (3.857)   Loss 0.2334 (0.2334)   Prec@1 90.625 (90.625)   Prec@5 100.000 (100.000)   [2019-08-30 21:20:36]
  Epoch: [015][200/391]   Time 0.497 (0.406)   Data 0.000 (0.019)   Loss 0.1263 (0.1524)   Prec@1 95.312 (94.694)   Prec@5 100.000 (99.938)   [2019-08-30 21:21:53]
  **Test** Prec@1 88.100 Prec@5 99.490 Error@1 11.900

==>>[2019-08-30 21:23:25] [Epoch=016/100] [Need: 03:55:23] [learning_rate=0.0100] [Best : Accuracy=88.95, Error=11.05]
  Epoch: [016][000/391]   Time 3.474 (3.474)   Data 2.897 (2.897)   Loss 0.1312 (0.1312)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-08-30 21:23:29]
  Epoch: [016][200/391]   Time 0.347 (0.391)   Data 0.000 (0.015)   Loss 0.0876 (0.1575)   Prec@1 96.875 (94.415)   Prec@5 100.000 (99.946)   [2019-08-30 21:24:44]
  **Test** Prec@1 88.430 Prec@5 99.620 Error@1 11.570

==>>[2019-08-30 21:26:18] [Epoch=017/100] [Need: 03:52:59] [learning_rate=0.0100] [Best : Accuracy=88.95, Error=11.05]
  Epoch: [017][000/391]   Time 4.090 (4.090)   Data 3.730 (3.730)   Loss 0.1345 (0.1345)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-30 21:26:22]
  Epoch: [017][200/391]   Time 0.412 (0.393)   Data 0.000 (0.019)   Loss 0.2054 (0.1580)   Prec@1 95.312 (94.387)   Prec@5 100.000 (99.942)   [2019-08-30 21:27:37]
  **Test** Prec@1 89.530 Prec@5 99.600 Error@1 10.470

==>>[2019-08-30 21:29:08] [Epoch=018/100] [Need: 03:50:20] [learning_rate=0.0100] [Best : Accuracy=89.53, Error=10.47]
  Epoch: [018][000/391]   Time 3.417 (3.417)   Data 2.976 (2.976)   Loss 0.0940 (0.0940)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-08-30 21:29:12]
  Epoch: [018][200/391]   Time 0.396 (0.397)   Data 0.000 (0.015)   Loss 0.2078 (0.1530)   Prec@1 93.750 (94.687)   Prec@5 100.000 (99.926)   [2019-08-30 21:30:28]
  **Test** Prec@1 86.880 Prec@5 99.510 Error@1 13.120

==>>[2019-08-30 21:32:05] [Epoch=019/100] [Need: 03:48:05] [learning_rate=0.0100] [Best : Accuracy=89.53, Error=10.47]
  Epoch: [019][000/391]   Time 3.468 (3.468)   Data 2.969 (2.969)   Loss 0.1691 (0.1691)   Prec@1 92.969 (92.969)   Prec@5 100.000 (100.000)   [2019-08-30 21:32:08]
  Epoch: [019][200/391]   Time 0.458 (0.395)   Data 0.000 (0.015)   Loss 0.1392 (0.1547)   Prec@1 94.531 (94.578)   Prec@5 100.000 (99.973)   [2019-08-30 21:33:24]
  **Test** Prec@1 88.810 Prec@5 99.610 Error@1 11.190

==>>[2019-08-30 21:34:53] [Epoch=020/100] [Need: 03:45:12] [learning_rate=0.0100] [Best : Accuracy=89.53, Error=10.47]
  Epoch: [020][000/391]   Time 3.655 (3.655)   Data 3.248 (3.248)   Loss 0.1236 (0.1236)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-08-30 21:34:56]
  Epoch: [020][200/391]   Time 0.374 (0.408)   Data 0.000 (0.016)   Loss 0.1715 (0.1566)   Prec@1 93.750 (94.578)   Prec@5 100.000 (99.930)   [2019-08-30 21:36:15]
  **Test** Prec@1 89.090 Prec@5 99.580 Error@1 10.910

==>>[2019-08-30 21:37:42] [Epoch=021/100] [Need: 03:42:25] [learning_rate=0.0100] [Best : Accuracy=89.53, Error=10.47]
  Epoch: [021][000/391]   Time 3.410 (3.410)   Data 3.025 (3.025)   Loss 0.0980 (0.0980)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-30 21:37:46]
  Epoch: [021][200/391]   Time 0.353 (0.391)   Data 0.000 (0.015)   Loss 0.2129 (0.1549)   Prec@1 94.531 (94.469)   Prec@5 99.219 (99.934)   [2019-08-30 21:39:01]
  **Test** Prec@1 88.420 Prec@5 99.520 Error@1 11.580

==>>[2019-08-30 21:40:33] [Epoch=022/100] [Need: 03:39:43] [learning_rate=0.0100] [Best : Accuracy=89.53, Error=10.47]
  Epoch: [022][000/391]   Time 3.899 (3.899)   Data 3.456 (3.456)   Loss 0.1964 (0.1964)   Prec@1 93.750 (93.750)   Prec@5 99.219 (99.219)   [2019-08-30 21:40:37]
  Epoch: [022][200/391]   Time 0.258 (0.397)   Data 0.000 (0.018)   Loss 0.2575 (0.1570)   Prec@1 92.188 (94.485)   Prec@5 100.000 (99.918)   [2019-08-30 21:41:53]
  **Test** Prec@1 87.810 Prec@5 99.520 Error@1 12.190

==>>[2019-08-30 21:43:25] [Epoch=023/100] [Need: 03:37:02] [learning_rate=0.0100] [Best : Accuracy=89.53, Error=10.47]
  Epoch: [023][000/391]   Time 3.643 (3.643)   Data 3.300 (3.300)   Loss 0.1080 (0.1080)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-30 21:43:28]
  Epoch: [023][200/391]   Time 0.296 (0.405)   Data 0.000 (0.017)   Loss 0.0870 (0.1502)   Prec@1 96.875 (94.597)   Prec@5 100.000 (99.942)   [2019-08-30 21:44:46]
  **Test** Prec@1 88.980 Prec@5 99.710 Error@1 11.020

==>>[2019-08-30 21:46:18] [Epoch=024/100] [Need: 03:34:28] [learning_rate=0.0100] [Best : Accuracy=89.53, Error=10.47]
  Epoch: [024][000/391]   Time 4.037 (4.037)   Data 3.612 (3.612)   Loss 0.1823 (0.1823)   Prec@1 92.188 (92.188)   Prec@5 100.000 (100.000)   [2019-08-30 21:46:22]
  Epoch: [024][200/391]   Time 0.347 (0.387)   Data 0.000 (0.018)   Loss 0.1291 (0.1530)   Prec@1 95.312 (94.426)   Prec@5 100.000 (99.942)   [2019-08-30 21:47:36]
  **Test** Prec@1 87.410 Prec@5 99.210 Error@1 12.590

==>>[2019-08-30 21:49:08] [Epoch=025/100] [Need: 03:31:37] [learning_rate=0.0100] [Best : Accuracy=89.53, Error=10.47]
  Epoch: [025][000/391]   Time 3.690 (3.690)   Data 3.156 (3.156)   Loss 0.2266 (0.2266)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-08-30 21:49:11]
  Epoch: [025][200/391]   Time 0.352 (0.398)   Data 0.000 (0.016)   Loss 0.1457 (0.1561)   Prec@1 93.750 (94.430)   Prec@5 100.000 (99.934)   [2019-08-30 21:50:28]
  **Test** Prec@1 88.800 Prec@5 99.670 Error@1 11.200

==>>[2019-08-30 21:51:57] [Epoch=026/100] [Need: 03:28:49] [learning_rate=0.0100] [Best : Accuracy=89.53, Error=10.47]
  Epoch: [026][000/391]   Time 4.422 (4.422)   Data 3.996 (3.996)   Loss 0.1245 (0.1245)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-08-30 21:52:02]
  Epoch: [026][200/391]   Time 0.331 (0.404)   Data 0.000 (0.020)   Loss 0.1031 (0.1554)   Prec@1 95.312 (94.454)   Prec@5 100.000 (99.953)   [2019-08-30 21:53:19]
  **Test** Prec@1 85.500 Prec@5 99.180 Error@1 14.500

==>>[2019-08-30 21:54:49] [Epoch=027/100] [Need: 03:26:05] [learning_rate=0.0100] [Best : Accuracy=89.53, Error=10.47]
  Epoch: [027][000/391]   Time 3.941 (3.941)   Data 3.607 (3.607)   Loss 0.1559 (0.1559)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-08-30 21:54:53]
  Epoch: [027][200/391]   Time 0.304 (0.389)   Data 0.000 (0.018)   Loss 0.1004 (0.1612)   Prec@1 95.312 (94.450)   Prec@5 100.000 (99.961)   [2019-08-30 21:56:07]
  **Test** Prec@1 85.920 Prec@5 99.580 Error@1 14.080

==>>[2019-08-30 21:57:36] [Epoch=028/100] [Need: 03:23:13] [learning_rate=0.0100] [Best : Accuracy=89.53, Error=10.47]
  Epoch: [028][000/391]   Time 4.140 (4.140)   Data 3.769 (3.769)   Loss 0.1327 (0.1327)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-08-30 21:57:41]
  Epoch: [028][200/391]   Time 0.244 (0.399)   Data 0.000 (0.019)   Loss 0.1281 (0.1584)   Prec@1 97.656 (94.356)   Prec@5 100.000 (99.934)   [2019-08-30 21:58:57]
  **Test** Prec@1 88.610 Prec@5 99.510 Error@1 11.390

==>>[2019-08-30 22:00:29] [Epoch=029/100] [Need: 03:20:32] [learning_rate=0.0100] [Best : Accuracy=89.53, Error=10.47]
  Epoch: [029][000/391]   Time 3.920 (3.920)   Data 3.410 (3.410)   Loss 0.1125 (0.1125)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-30 22:00:33]
  Epoch: [029][200/391]   Time 0.466 (0.397)   Data 0.000 (0.017)   Loss 0.1926 (0.1575)   Prec@1 94.531 (94.317)   Prec@5 100.000 (99.934)   [2019-08-30 22:01:49]
  **Test** Prec@1 87.380 Prec@5 99.650 Error@1 12.620

==>>[2019-08-30 22:03:19] [Epoch=030/100] [Need: 03:17:42] [learning_rate=0.0010] [Best : Accuracy=89.53, Error=10.47]
  Epoch: [030][000/391]   Time 3.515 (3.515)   Data 3.152 (3.152)   Loss 0.1437 (0.1437)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-08-30 22:03:23]
  Epoch: [030][200/391]   Time 0.414 (0.383)   Data 0.000 (0.016)   Loss 0.1180 (0.1286)   Prec@1 96.094 (95.546)   Prec@5 99.219 (99.942)   [2019-08-30 22:04:36]
  **Test** Prec@1 90.880 Prec@5 99.680 Error@1 9.120

==>>[2019-08-30 22:06:02] [Epoch=031/100] [Need: 03:14:38] [learning_rate=0.0010] [Best : Accuracy=90.88, Error=9.12]
  Epoch: [031][000/391]   Time 4.642 (4.642)   Data 4.242 (4.242)   Loss 0.0981 (0.0981)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-08-30 22:06:06]
  Epoch: [031][200/391]   Time 0.452 (0.380)   Data 0.000 (0.021)   Loss 0.0687 (0.1068)   Prec@1 97.656 (96.409)   Prec@5 100.000 (99.969)   [2019-08-30 22:07:18]
  **Test** Prec@1 90.670 Prec@5 99.680 Error@1 9.330

==>>[2019-08-30 22:08:44] [Epoch=032/100] [Need: 03:11:35] [learning_rate=0.0010] [Best : Accuracy=90.88, Error=9.12]
  Epoch: [032][000/391]   Time 3.376 (3.376)   Data 2.911 (2.911)   Loss 0.1247 (0.1247)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-08-30 22:08:48]
  Epoch: [032][200/391]   Time 0.342 (0.372)   Data 0.000 (0.015)   Loss 0.0980 (0.1061)   Prec@1 97.656 (96.409)   Prec@5 100.000 (99.957)   [2019-08-30 22:09:59]
  **Test** Prec@1 90.570 Prec@5 99.700 Error@1 9.430

==>>[2019-08-30 22:11:26] [Epoch=033/100] [Need: 03:08:31] [learning_rate=0.0010] [Best : Accuracy=90.88, Error=9.12]
  Epoch: [033][000/391]   Time 3.866 (3.866)   Data 3.226 (3.226)   Loss 0.0954 (0.0954)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-30 22:11:30]
  Epoch: [033][200/391]   Time 0.352 (0.373)   Data 0.000 (0.016)   Loss 0.0748 (0.0992)   Prec@1 97.656 (96.770)   Prec@5 100.000 (99.965)   [2019-08-30 22:12:41]
  **Test** Prec@1 90.940 Prec@5 99.670 Error@1 9.060

==>>[2019-08-30 22:14:05] [Epoch=034/100] [Need: 03:05:24] [learning_rate=0.0010] [Best : Accuracy=90.94, Error=9.06]
  Epoch: [034][000/391]   Time 2.912 (2.912)   Data 2.534 (2.534)   Loss 0.1301 (0.1301)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-08-30 22:14:08]
  Epoch: [034][200/391]   Time 0.499 (0.381)   Data 0.000 (0.013)   Loss 0.1689 (0.1013)   Prec@1 94.531 (96.556)   Prec@5 100.000 (99.988)   [2019-08-30 22:15:22]
  **Test** Prec@1 90.840 Prec@5 99.700 Error@1 9.160

==>>[2019-08-30 22:16:52] [Epoch=035/100] [Need: 03:02:31] [learning_rate=0.0010] [Best : Accuracy=90.94, Error=9.06]
  Epoch: [035][000/391]   Time 3.438 (3.438)   Data 2.973 (2.973)   Loss 0.0769 (0.0769)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-08-30 22:16:55]
  Epoch: [035][200/391]   Time 0.391 (0.397)   Data 0.000 (0.015)   Loss 0.1046 (0.0968)   Prec@1 96.875 (96.813)   Prec@5 100.000 (99.961)   [2019-08-30 22:18:11]
  **Test** Prec@1 90.520 Prec@5 99.690 Error@1 9.480

==>>[2019-08-30 22:19:44] [Epoch=036/100] [Need: 02:59:49] [learning_rate=0.0010] [Best : Accuracy=90.94, Error=9.06]
  Epoch: [036][000/391]   Time 4.607 (4.607)   Data 3.949 (3.949)   Loss 0.1078 (0.1078)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-08-30 22:19:48]
  Epoch: [036][200/391]   Time 0.330 (0.415)   Data 0.000 (0.020)   Loss 0.0777 (0.0942)   Prec@1 97.656 (96.828)   Prec@5 100.000 (99.988)   [2019-08-30 22:21:07]
  **Test** Prec@1 90.790 Prec@5 99.750 Error@1 9.210

==>>[2019-08-30 22:22:38] [Epoch=037/100] [Need: 02:57:10] [learning_rate=0.0010] [Best : Accuracy=90.94, Error=9.06]
  Epoch: [037][000/391]   Time 2.229 (2.229)   Data 1.851 (1.851)   Loss 0.1035 (0.1035)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-08-30 22:22:40]
  Epoch: [037][200/391]   Time 0.499 (0.387)   Data 0.000 (0.009)   Loss 0.1001 (0.0950)   Prec@1 96.875 (96.821)   Prec@5 100.000 (99.981)   [2019-08-30 22:23:56]
  **Test** Prec@1 90.900 Prec@5 99.720 Error@1 9.100

==>>[2019-08-30 22:25:28] [Epoch=038/100] [Need: 02:54:22] [learning_rate=0.0010] [Best : Accuracy=90.94, Error=9.06]
  Epoch: [038][000/391]   Time 2.671 (2.671)   Data 2.301 (2.301)   Loss 0.0640 (0.0640)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-08-30 22:25:30]
  Epoch: [038][200/391]   Time 0.331 (0.389)   Data 0.000 (0.012)   Loss 0.0893 (0.0899)   Prec@1 97.656 (96.879)   Prec@5 100.000 (99.969)   [2019-08-30 22:26:46]
  **Test** Prec@1 91.110 Prec@5 99.710 Error@1 8.890

==>>[2019-08-30 22:28:19] [Epoch=039/100] [Need: 02:51:39] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [039][000/391]   Time 2.973 (2.973)   Data 2.586 (2.586)   Loss 0.0681 (0.0681)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-08-30 22:28:22]
  Epoch: [039][200/391]   Time 0.421 (0.370)   Data 0.000 (0.014)   Loss 0.0619 (0.0930)   Prec@1 97.656 (96.832)   Prec@5 100.000 (99.992)   [2019-08-30 22:29:34]
  **Test** Prec@1 91.090 Prec@5 99.710 Error@1 8.910

==>>[2019-08-30 22:31:04] [Epoch=040/100] [Need: 02:48:43] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [040][000/391]   Time 4.770 (4.770)   Data 4.316 (4.316)   Loss 0.1146 (0.1146)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-08-30 22:31:09]
  Epoch: [040][200/391]   Time 0.566 (0.402)   Data 0.000 (0.022)   Loss 0.0995 (0.0944)   Prec@1 96.875 (96.918)   Prec@5 100.000 (99.977)   [2019-08-30 22:32:25]
  **Test** Prec@1 91.060 Prec@5 99.720 Error@1 8.940

==>>[2019-08-30 22:33:58] [Epoch=041/100] [Need: 02:46:01] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [041][000/391]   Time 4.877 (4.877)   Data 4.407 (4.407)   Loss 0.0851 (0.0851)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-08-30 22:34:03]
  Epoch: [041][200/391]   Time 0.487 (0.389)   Data 0.000 (0.023)   Loss 0.1071 (0.0910)   Prec@1 96.875 (96.906)   Prec@5 100.000 (99.977)   [2019-08-30 22:35:16]
  **Test** Prec@1 90.620 Prec@5 99.710 Error@1 9.380

==>>[2019-08-30 22:36:48] [Epoch=042/100] [Need: 02:43:15] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [042][000/391]   Time 5.296 (5.296)   Data 4.875 (4.875)   Loss 0.0556 (0.0556)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-30 22:36:53]
  Epoch: [042][200/391]   Time 0.505 (0.400)   Data 0.000 (0.025)   Loss 0.1002 (0.0878)   Prec@1 96.875 (97.077)   Prec@5 100.000 (99.996)   [2019-08-30 22:38:08]
  **Test** Prec@1 90.790 Prec@5 99.670 Error@1 9.210

==>>[2019-08-30 22:39:41] [Epoch=043/100] [Need: 02:40:31] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [043][000/391]   Time 4.426 (4.426)   Data 3.836 (3.836)   Loss 0.0883 (0.0883)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-08-30 22:39:46]
  Epoch: [043][200/391]   Time 0.374 (0.396)   Data 0.000 (0.019)   Loss 0.1234 (0.0884)   Prec@1 95.312 (96.984)   Prec@5 100.000 (99.996)   [2019-08-30 22:41:01]
  **Test** Prec@1 90.780 Prec@5 99.730 Error@1 9.220

==>>[2019-08-30 22:42:29] [Epoch=044/100] [Need: 02:37:42] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [044][000/391]   Time 5.133 (5.133)   Data 4.709 (4.709)   Loss 0.0574 (0.0574)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-08-30 22:42:34]
  Epoch: [044][200/391]   Time 0.306 (0.392)   Data 0.000 (0.024)   Loss 0.0651 (0.0866)   Prec@1 97.656 (97.100)   Prec@5 100.000 (99.973)   [2019-08-30 22:43:48]
  **Test** Prec@1 90.680 Prec@5 99.760 Error@1 9.320

==>>[2019-08-30 22:45:20] [Epoch=045/100] [Need: 02:34:55] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [045][000/391]   Time 2.950 (2.950)   Data 2.385 (2.385)   Loss 0.1411 (0.1411)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-08-30 22:45:23]
  Epoch: [045][200/391]   Time 0.311 (0.383)   Data 0.000 (0.012)   Loss 0.0899 (0.0914)   Prec@1 95.312 (96.867)   Prec@5 100.000 (99.977)   [2019-08-30 22:46:37]
  **Test** Prec@1 90.200 Prec@5 99.640 Error@1 9.800

==>>[2019-08-30 22:48:09] [Epoch=046/100] [Need: 02:32:06] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [046][000/391]   Time 2.884 (2.884)   Data 2.589 (2.589)   Loss 0.0932 (0.0932)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-30 22:48:12]
  Epoch: [046][200/391]   Time 0.359 (0.385)   Data 0.000 (0.013)   Loss 0.0778 (0.0913)   Prec@1 97.656 (96.821)   Prec@5 100.000 (99.984)   [2019-08-30 22:49:26]
  **Test** Prec@1 90.570 Prec@5 99.680 Error@1 9.430

==>>[2019-08-30 22:51:02] [Epoch=047/100] [Need: 02:29:21] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [047][000/391]   Time 2.288 (2.288)   Data 1.761 (1.761)   Loss 0.0923 (0.0923)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-08-30 22:51:04]
  Epoch: [047][200/391]   Time 0.392 (0.381)   Data 0.000 (0.009)   Loss 0.0639 (0.0856)   Prec@1 98.438 (97.108)   Prec@5 100.000 (99.984)   [2019-08-30 22:52:18]
  **Test** Prec@1 90.350 Prec@5 99.540 Error@1 9.650

==>>[2019-08-30 22:53:50] [Epoch=048/100] [Need: 02:26:31] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [048][000/391]   Time 3.508 (3.508)   Data 3.161 (3.161)   Loss 0.0539 (0.0539)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-08-30 22:53:53]
  Epoch: [048][200/391]   Time 0.375 (0.392)   Data 0.000 (0.016)   Loss 0.0925 (0.0913)   Prec@1 98.438 (96.984)   Prec@5 100.000 (99.996)   [2019-08-30 22:55:09]
  **Test** Prec@1 90.280 Prec@5 99.720 Error@1 9.720

==>>[2019-08-30 22:56:41] [Epoch=049/100] [Need: 02:23:44] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [049][000/391]   Time 3.406 (3.406)   Data 2.880 (2.880)   Loss 0.1171 (0.1171)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-08-30 22:56:44]
  Epoch: [049][200/391]   Time 0.424 (0.387)   Data 0.000 (0.015)   Loss 0.0736 (0.0860)   Prec@1 96.875 (97.139)   Prec@5 100.000 (99.988)   [2019-08-30 22:57:59]
  **Test** Prec@1 90.390 Prec@5 99.740 Error@1 9.610

==>>[2019-08-30 22:59:34] [Epoch=050/100] [Need: 02:20:58] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [050][000/391]   Time 3.564 (3.564)   Data 3.109 (3.109)   Loss 0.0433 (0.0433)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-08-30 22:59:37]
  Epoch: [050][200/391]   Time 0.478 (0.385)   Data 0.000 (0.016)   Loss 0.0875 (0.0906)   Prec@1 96.875 (96.863)   Prec@5 100.000 (99.988)   [2019-08-30 23:00:51]
  **Test** Prec@1 89.480 Prec@5 99.650 Error@1 10.520

==>>[2019-08-30 23:02:27] [Epoch=051/100] [Need: 02:18:14] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [051][000/391]   Time 3.622 (3.622)   Data 3.253 (3.253)   Loss 0.0861 (0.0861)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-08-30 23:02:31]
  Epoch: [051][200/391]   Time 0.237 (0.384)   Data 0.000 (0.017)   Loss 0.1023 (0.0867)   Prec@1 96.875 (97.085)   Prec@5 100.000 (99.996)   [2019-08-30 23:03:44]
  **Test** Prec@1 90.140 Prec@5 99.700 Error@1 9.860

==>>[2019-08-30 23:05:21] [Epoch=052/100] [Need: 02:15:28] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [052][000/391]   Time 3.552 (3.552)   Data 3.122 (3.122)   Loss 0.0950 (0.0950)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-08-30 23:05:24]
  Epoch: [052][200/391]   Time 0.365 (0.392)   Data 0.000 (0.016)   Loss 0.0447 (0.0902)   Prec@1 98.438 (96.984)   Prec@5 100.000 (99.988)   [2019-08-30 23:06:40]
  **Test** Prec@1 90.250 Prec@5 99.620 Error@1 9.750

==>>[2019-08-30 23:08:14] [Epoch=053/100] [Need: 02:12:42] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [053][000/391]   Time 2.221 (2.221)   Data 1.903 (1.903)   Loss 0.1450 (0.1450)   Prec@1 94.531 (94.531)   Prec@5 100.000 (100.000)   [2019-08-30 23:08:16]
  Epoch: [053][200/391]   Time 0.386 (0.389)   Data 0.000 (0.010)   Loss 0.0407 (0.0911)   Prec@1 99.219 (96.995)   Prec@5 100.000 (99.988)   [2019-08-30 23:09:32]
  **Test** Prec@1 90.320 Prec@5 99.720 Error@1 9.680

==>>[2019-08-30 23:11:05] [Epoch=054/100] [Need: 02:09:53] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [054][000/391]   Time 4.596 (4.596)   Data 4.273 (4.273)   Loss 0.0999 (0.0999)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-08-30 23:11:09]
  Epoch: [054][200/391]   Time 0.402 (0.401)   Data 0.000 (0.022)   Loss 0.1233 (0.0887)   Prec@1 93.750 (96.918)   Prec@5 100.000 (99.981)   [2019-08-30 23:12:25]
  **Test** Prec@1 90.200 Prec@5 99.710 Error@1 9.800

==>>[2019-08-30 23:13:57] [Epoch=055/100] [Need: 02:07:06] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [055][000/391]   Time 4.009 (4.009)   Data 3.613 (3.613)   Loss 0.1020 (0.1020)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-30 23:14:01]
  Epoch: [055][200/391]   Time 0.371 (0.382)   Data 0.000 (0.018)   Loss 0.0718 (0.0895)   Prec@1 99.219 (97.038)   Prec@5 100.000 (99.965)   [2019-08-30 23:15:13]
  **Test** Prec@1 90.480 Prec@5 99.730 Error@1 9.520

==>>[2019-08-30 23:16:45] [Epoch=056/100] [Need: 02:04:16] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [056][000/391]   Time 4.964 (4.964)   Data 4.592 (4.592)   Loss 0.0724 (0.0724)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-08-30 23:16:50]
  Epoch: [056][200/391]   Time 0.433 (0.392)   Data 0.000 (0.023)   Loss 0.1541 (0.0856)   Prec@1 95.312 (97.135)   Prec@5 100.000 (99.984)   [2019-08-30 23:18:04]
  **Test** Prec@1 90.850 Prec@5 99.680 Error@1 9.150

==>>[2019-08-30 23:19:40] [Epoch=057/100] [Need: 02:01:31] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [057][000/391]   Time 4.275 (4.275)   Data 3.697 (3.697)   Loss 0.0665 (0.0665)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-30 23:19:44]
  Epoch: [057][200/391]   Time 0.342 (0.388)   Data 0.000 (0.019)   Loss 0.0920 (0.0880)   Prec@1 96.875 (96.910)   Prec@5 100.000 (99.977)   [2019-08-30 23:20:58]
  **Test** Prec@1 89.820 Prec@5 99.690 Error@1 10.180

==>>[2019-08-30 23:22:31] [Epoch=058/100] [Need: 01:58:42] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [058][000/391]   Time 4.866 (4.866)   Data 4.401 (4.401)   Loss 0.0561 (0.0561)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-08-30 23:22:35]
  Epoch: [058][200/391]   Time 0.321 (0.392)   Data 0.000 (0.022)   Loss 0.0764 (0.0889)   Prec@1 96.875 (96.972)   Prec@5 100.000 (99.984)   [2019-08-30 23:23:49]
  **Test** Prec@1 90.990 Prec@5 99.730 Error@1 9.010

==>>[2019-08-30 23:25:25] [Epoch=059/100] [Need: 01:55:55] [learning_rate=0.0010] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [059][000/391]   Time 3.708 (3.708)   Data 3.093 (3.093)   Loss 0.1105 (0.1105)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-30 23:25:29]
  Epoch: [059][200/391]   Time 0.382 (0.388)   Data 0.000 (0.016)   Loss 0.0494 (0.0880)   Prec@1 99.219 (96.906)   Prec@5 100.000 (99.984)   [2019-08-30 23:26:43]
  **Test** Prec@1 90.440 Prec@5 99.640 Error@1 9.560

==>>[2019-08-30 23:28:19] [Epoch=060/100] [Need: 01:53:09] [learning_rate=0.0001] [Best : Accuracy=91.11, Error=8.89]
  Epoch: [060][000/391]   Time 5.001 (5.001)   Data 4.362 (4.362)   Loss 0.0488 (0.0488)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-08-30 23:28:24]
  Epoch: [060][200/391]   Time 0.386 (0.392)   Data 0.000 (0.022)   Loss 0.0952 (0.0836)   Prec@1 97.656 (97.139)   Prec@5 100.000 (99.996)   [2019-08-30 23:29:38]
  **Test** Prec@1 91.310 Prec@5 99.730 Error@1 8.690

==>>[2019-08-30 23:31:12] [Epoch=061/100] [Need: 01:50:21] [learning_rate=0.0001] [Best : Accuracy=91.31, Error=8.69]
  Epoch: [061][000/391]   Time 3.952 (3.952)   Data 3.389 (3.389)   Loss 0.0664 (0.0664)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-08-30 23:31:16]
  Epoch: [061][200/391]   Time 0.493 (0.394)   Data 0.000 (0.017)   Loss 0.0788 (0.0776)   Prec@1 97.656 (97.380)   Prec@5 100.000 (99.992)   [2019-08-30 23:32:32]
  **Test** Prec@1 91.040 Prec@5 99.720 Error@1 8.960

==>>[2019-08-30 23:34:03] [Epoch=062/100] [Need: 01:47:33] [learning_rate=0.0001] [Best : Accuracy=91.31, Error=8.69]
  Epoch: [062][000/391]   Time 3.767 (3.767)   Data 3.215 (3.215)   Loss 0.0973 (0.0973)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-08-30 23:34:07]
  Epoch: [062][200/391]   Time 0.213 (0.383)   Data 0.000 (0.016)   Loss 0.0869 (0.0716)   Prec@1 97.656 (97.761)   Prec@5 100.000 (99.977)   [2019-08-30 23:35:20]
  **Test** Prec@1 91.250 Prec@5 99.700 Error@1 8.750

==>>[2019-08-30 23:36:55] [Epoch=063/100] [Need: 01:44:44] [learning_rate=0.0001] [Best : Accuracy=91.31, Error=8.69]
  Epoch: [063][000/391]   Time 3.817 (3.817)   Data 3.378 (3.378)   Loss 0.0590 (0.0590)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-30 23:36:59]
  Epoch: [063][200/391]   Time 0.402 (0.379)   Data 0.000 (0.017)   Loss 0.0534 (0.0720)   Prec@1 98.438 (97.602)   Prec@5 100.000 (99.984)   [2019-08-30 23:38:11]
  **Test** Prec@1 91.420 Prec@5 99.720 Error@1 8.580

==>>[2019-08-30 23:39:45] [Epoch=064/100] [Need: 01:41:54] [learning_rate=0.0001] [Best : Accuracy=91.42, Error=8.58]
  Epoch: [064][000/391]   Time 3.905 (3.905)   Data 3.433 (3.433)   Loss 0.0935 (0.0935)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-08-30 23:39:49]
  Epoch: [064][200/391]   Time 0.376 (0.388)   Data 0.000 (0.017)   Loss 0.1203 (0.0733)   Prec@1 95.312 (97.598)   Prec@5 99.219 (99.992)   [2019-08-30 23:41:03]
  **Test** Prec@1 91.080 Prec@5 99.750 Error@1 8.920

==>>[2019-08-30 23:42:38] [Epoch=065/100] [Need: 01:39:06] [learning_rate=0.0001] [Best : Accuracy=91.42, Error=8.58]
  Epoch: [065][000/391]   Time 3.449 (3.449)   Data 2.989 (2.989)   Loss 0.0322 (0.0322)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-08-30 23:42:41]
  Epoch: [065][200/391]   Time 0.330 (0.391)   Data 0.000 (0.015)   Loss 0.1063 (0.0730)   Prec@1 94.531 (97.629)   Prec@5 100.000 (99.992)   [2019-08-30 23:43:56]
  **Test** Prec@1 91.080 Prec@5 99.720 Error@1 8.920

==>>[2019-08-30 23:45:30] [Epoch=066/100] [Need: 01:36:17] [learning_rate=0.0001] [Best : Accuracy=91.42, Error=8.58]
  Epoch: [066][000/391]   Time 3.343 (3.343)   Data 2.939 (2.939)   Loss 0.0421 (0.0421)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-08-30 23:45:33]
  Epoch: [066][200/391]   Time 0.386 (0.387)   Data 0.000 (0.015)   Loss 0.0818 (0.0713)   Prec@1 97.656 (97.645)   Prec@5 100.000 (99.988)   [2019-08-30 23:46:47]
  **Test** Prec@1 91.120 Prec@5 99.700 Error@1 8.880

==>>[2019-08-30 23:48:20] [Epoch=067/100] [Need: 01:33:27] [learning_rate=0.0001] [Best : Accuracy=91.42, Error=8.58]
  Epoch: [067][000/391]   Time 2.825 (2.825)   Data 2.413 (2.413)   Loss 0.0541 (0.0541)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-08-30 23:48:23]
  Epoch: [067][200/391]   Time 0.273 (0.386)   Data 0.000 (0.012)   Loss 0.0706 (0.0674)   Prec@1 96.875 (97.753)   Prec@5 100.000 (99.996)   [2019-08-30 23:49:38]
  **Test** Prec@1 91.520 Prec@5 99.690 Error@1 8.480

==>>[2019-08-30 23:51:13] [Epoch=068/100] [Need: 01:30:39] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [068][000/391]   Time 2.554 (2.554)   Data 2.097 (2.097)   Loss 0.0711 (0.0711)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-08-30 23:51:16]
  Epoch: [068][200/391]   Time 0.359 (0.382)   Data 0.000 (0.011)   Loss 0.0511 (0.0743)   Prec@1 98.438 (97.590)   Prec@5 100.000 (99.992)   [2019-08-30 23:52:30]
  **Test** Prec@1 91.300 Prec@5 99.710 Error@1 8.700

==>>[2019-08-30 23:54:04] [Epoch=069/100] [Need: 01:27:49] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [069][000/391]   Time 3.776 (3.776)   Data 3.394 (3.394)   Loss 0.0762 (0.0762)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-30 23:54:07]
  Epoch: [069][200/391]   Time 0.262 (0.382)   Data 0.000 (0.017)   Loss 0.0760 (0.0722)   Prec@1 96.094 (97.602)   Prec@5 100.000 (99.984)   [2019-08-30 23:55:20]
  **Test** Prec@1 91.370 Prec@5 99.680 Error@1 8.630

==>>[2019-08-30 23:56:53] [Epoch=070/100] [Need: 01:24:59] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [070][000/391]   Time 3.369 (3.369)   Data 2.915 (2.915)   Loss 0.0796 (0.0796)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-08-30 23:56:56]
  Epoch: [070][200/391]   Time 0.368 (0.385)   Data 0.000 (0.015)   Loss 0.0925 (0.0734)   Prec@1 97.656 (97.575)   Prec@5 100.000 (100.000)   [2019-08-30 23:58:10]
  **Test** Prec@1 91.010 Prec@5 99.730 Error@1 8.990

==>>[2019-08-30 23:59:43] [Epoch=071/100] [Need: 01:22:09] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [071][000/391]   Time 3.520 (3.520)   Data 3.069 (3.069)   Loss 0.1175 (0.1175)   Prec@1 96.094 (96.094)   Prec@5 100.000 (100.000)   [2019-08-30 23:59:47]
  Epoch: [071][200/391]   Time 0.315 (0.389)   Data 0.000 (0.016)   Loss 0.0598 (0.0708)   Prec@1 98.438 (97.715)   Prec@5 100.000 (99.996)   [2019-08-31 00:01:01]
  **Test** Prec@1 91.380 Prec@5 99.680 Error@1 8.620

==>>[2019-08-31 00:02:34] [Epoch=072/100] [Need: 01:19:19] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [072][000/391]   Time 4.180 (4.180)   Data 3.662 (3.662)   Loss 0.0571 (0.0571)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-08-31 00:02:39]
  Epoch: [072][200/391]   Time 0.496 (0.390)   Data 0.000 (0.019)   Loss 0.0303 (0.0726)   Prec@1 99.219 (97.598)   Prec@5 100.000 (99.996)   [2019-08-31 00:03:53]
  **Test** Prec@1 91.310 Prec@5 99.730 Error@1 8.690

==>>[2019-08-31 00:05:27] [Epoch=073/100] [Need: 01:16:30] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [073][000/391]   Time 3.429 (3.429)   Data 3.044 (3.044)   Loss 0.0449 (0.0449)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-08-31 00:05:30]
  Epoch: [073][200/391]   Time 0.336 (0.391)   Data 0.000 (0.016)   Loss 0.0720 (0.0729)   Prec@1 98.438 (97.571)   Prec@5 100.000 (99.992)   [2019-08-31 00:06:45]
  **Test** Prec@1 91.460 Prec@5 99.700 Error@1 8.540

==>>[2019-08-31 00:08:17] [Epoch=074/100] [Need: 01:13:40] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [074][000/391]   Time 4.451 (4.451)   Data 4.063 (4.063)   Loss 0.0561 (0.0561)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-08-31 00:08:21]
  Epoch: [074][200/391]   Time 0.341 (0.386)   Data 0.000 (0.021)   Loss 0.0761 (0.0732)   Prec@1 98.438 (97.579)   Prec@5 100.000 (99.992)   [2019-08-31 00:09:35]
  **Test** Prec@1 90.820 Prec@5 99.740 Error@1 9.180

==>>[2019-08-31 00:11:08] [Epoch=075/100] [Need: 01:10:51] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [075][000/391]   Time 3.945 (3.945)   Data 3.550 (3.550)   Loss 0.0584 (0.0584)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-08-31 00:11:12]
  Epoch: [075][200/391]   Time 0.374 (0.394)   Data 0.000 (0.019)   Loss 0.0417 (0.0754)   Prec@1 99.219 (97.528)   Prec@5 100.000 (99.996)   [2019-08-31 00:12:27]
  **Test** Prec@1 91.250 Prec@5 99.780 Error@1 8.750

==>>[2019-08-31 00:14:00] [Epoch=076/100] [Need: 01:08:01] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [076][000/391]   Time 3.366 (3.366)   Data 2.932 (2.932)   Loss 0.0774 (0.0774)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-31 00:14:04]
  Epoch: [076][200/391]   Time 0.431 (0.392)   Data 0.000 (0.015)   Loss 0.0645 (0.0690)   Prec@1 96.094 (97.769)   Prec@5 100.000 (99.981)   [2019-08-31 00:15:19]
  **Test** Prec@1 91.210 Prec@5 99.700 Error@1 8.790

==>>[2019-08-31 00:16:52] [Epoch=077/100] [Need: 01:05:12] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [077][000/391]   Time 3.702 (3.702)   Data 3.248 (3.248)   Loss 0.0315 (0.0315)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-08-31 00:16:56]
  Epoch: [077][200/391]   Time 0.369 (0.414)   Data 0.000 (0.016)   Loss 0.0632 (0.0735)   Prec@1 98.438 (97.687)   Prec@5 100.000 (99.988)   [2019-08-31 00:18:16]
  **Test** Prec@1 90.910 Prec@5 99.710 Error@1 9.090

==>>[2019-08-31 00:19:46] [Epoch=078/100] [Need: 01:02:23] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [078][000/391]   Time 4.326 (4.326)   Data 3.902 (3.902)   Loss 0.0781 (0.0781)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-31 00:19:51]
  Epoch: [078][200/391]   Time 0.406 (0.400)   Data 0.000 (0.020)   Loss 0.0783 (0.0711)   Prec@1 97.656 (97.676)   Prec@5 100.000 (99.984)   [2019-08-31 00:21:07]
  **Test** Prec@1 91.260 Prec@5 99.710 Error@1 8.740

==>>[2019-08-31 00:22:38] [Epoch=079/100] [Need: 00:59:33] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [079][000/391]   Time 3.298 (3.298)   Data 2.721 (2.721)   Loss 0.0356 (0.0356)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-08-31 00:22:41]
  Epoch: [079][200/391]   Time 0.292 (0.385)   Data 0.000 (0.014)   Loss 0.0518 (0.0750)   Prec@1 99.219 (97.547)   Prec@5 100.000 (99.992)   [2019-08-31 00:23:55]
  **Test** Prec@1 91.010 Prec@5 99.710 Error@1 8.990

==>>[2019-08-31 00:25:29] [Epoch=080/100] [Need: 00:56:43] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [080][000/391]   Time 2.885 (2.885)   Data 2.415 (2.415)   Loss 0.0576 (0.0576)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-08-31 00:25:32]
  Epoch: [080][200/391]   Time 0.376 (0.378)   Data 0.000 (0.012)   Loss 0.0413 (0.0677)   Prec@1 98.438 (97.773)   Prec@5 100.000 (99.992)   [2019-08-31 00:26:45]
  **Test** Prec@1 91.290 Prec@5 99.700 Error@1 8.710

==>>[2019-08-31 00:28:21] [Epoch=081/100] [Need: 00:53:53] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [081][000/391]   Time 3.342 (3.342)   Data 2.946 (2.946)   Loss 0.0538 (0.0538)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-08-31 00:28:25]
  Epoch: [081][200/391]   Time 0.362 (0.387)   Data 0.000 (0.015)   Loss 0.1104 (0.0706)   Prec@1 96.094 (97.633)   Prec@5 100.000 (99.996)   [2019-08-31 00:29:39]
  **Test** Prec@1 90.970 Prec@5 99.710 Error@1 9.030

==>>[2019-08-31 00:31:10] [Epoch=082/100] [Need: 00:51:03] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [082][000/391]   Time 4.869 (4.869)   Data 4.371 (4.371)   Loss 0.0687 (0.0687)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-08-31 00:31:15]
  Epoch: [082][200/391]   Time 0.296 (0.400)   Data 0.000 (0.022)   Loss 0.0732 (0.0704)   Prec@1 96.875 (97.726)   Prec@5 100.000 (99.992)   [2019-08-31 00:32:30]
  **Test** Prec@1 91.100 Prec@5 99.690 Error@1 8.900

==>>[2019-08-31 00:34:04] [Epoch=083/100] [Need: 00:48:13] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [083][000/391]   Time 4.237 (4.237)   Data 3.721 (3.721)   Loss 0.0238 (0.0238)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-08-31 00:34:08]
  Epoch: [083][200/391]   Time 0.271 (0.400)   Data 0.000 (0.019)   Loss 0.0566 (0.0722)   Prec@1 98.438 (97.532)   Prec@5 100.000 (99.992)   [2019-08-31 00:35:25]
  **Test** Prec@1 91.220 Prec@5 99.660 Error@1 8.780

==>>[2019-08-31 00:36:55] [Epoch=084/100] [Need: 00:45:23] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [084][000/391]   Time 4.667 (4.667)   Data 4.173 (4.173)   Loss 0.1132 (0.1132)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-08-31 00:36:59]
  Epoch: [084][200/391]   Time 0.371 (0.404)   Data 0.000 (0.021)   Loss 0.0689 (0.0721)   Prec@1 96.875 (97.629)   Prec@5 100.000 (99.988)   [2019-08-31 00:38:16]
  **Test** Prec@1 91.250 Prec@5 99.740 Error@1 8.750

==>>[2019-08-31 00:39:45] [Epoch=085/100] [Need: 00:42:33] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [085][000/391]   Time 4.008 (4.008)   Data 3.589 (3.589)   Loss 0.0543 (0.0543)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-08-31 00:39:49]
  Epoch: [085][200/391]   Time 0.352 (0.401)   Data 0.000 (0.018)   Loss 0.0950 (0.0718)   Prec@1 96.094 (97.613)   Prec@5 100.000 (99.996)   [2019-08-31 00:41:06]
  **Test** Prec@1 90.440 Prec@5 99.700 Error@1 9.560

==>>[2019-08-31 00:42:38] [Epoch=086/100] [Need: 00:39:43] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [086][000/391]   Time 3.266 (3.266)   Data 2.913 (2.913)   Loss 0.1268 (0.1268)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-31 00:42:41]
  Epoch: [086][200/391]   Time 0.359 (0.385)   Data 0.000 (0.015)   Loss 0.0681 (0.0702)   Prec@1 97.656 (97.691)   Prec@5 100.000 (99.996)   [2019-08-31 00:43:56]
  **Test** Prec@1 90.910 Prec@5 99.700 Error@1 9.090

==>>[2019-08-31 00:45:29] [Epoch=087/100] [Need: 00:36:53] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [087][000/391]   Time 3.879 (3.879)   Data 3.466 (3.466)   Loss 0.0472 (0.0472)   Prec@1 100.000 (100.000)   Prec@5 100.000 (100.000)   [2019-08-31 00:45:33]
  Epoch: [087][200/391]   Time 0.483 (0.401)   Data 0.000 (0.018)   Loss 0.0715 (0.0689)   Prec@1 97.656 (97.765)   Prec@5 99.219 (99.984)   [2019-08-31 00:46:49]
  **Test** Prec@1 90.960 Prec@5 99.650 Error@1 9.040

==>>[2019-08-31 00:48:20] [Epoch=088/100] [Need: 00:34:03] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [088][000/391]   Time 3.138 (3.138)   Data 2.662 (2.662)   Loss 0.0973 (0.0973)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-31 00:48:24]
  Epoch: [088][200/391]   Time 0.472 (0.398)   Data 0.010 (0.014)   Loss 0.0472 (0.0734)   Prec@1 98.438 (97.645)   Prec@5 100.000 (99.984)   [2019-08-31 00:49:40]
  **Test** Prec@1 90.070 Prec@5 99.720 Error@1 9.930

==>>[2019-08-31 00:51:12] [Epoch=089/100] [Need: 00:31:13] [learning_rate=0.0001] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [089][000/391]   Time 3.037 (3.037)   Data 2.493 (2.493)   Loss 0.0746 (0.0746)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-31 00:51:15]
  Epoch: [089][200/391]   Time 0.362 (0.402)   Data 0.000 (0.013)   Loss 0.0630 (0.0711)   Prec@1 99.219 (97.648)   Prec@5 100.000 (99.992)   [2019-08-31 00:52:33]
  **Test** Prec@1 91.290 Prec@5 99.730 Error@1 8.710

==>>[2019-08-31 00:54:06] [Epoch=090/100] [Need: 00:28:23] [learning_rate=0.0000] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [090][000/391]   Time 3.115 (3.115)   Data 2.441 (2.441)   Loss 0.0792 (0.0792)   Prec@1 96.875 (96.875)   Prec@5 100.000 (100.000)   [2019-08-31 00:54:09]
  Epoch: [090][200/391]   Time 0.390 (0.407)   Data 0.000 (0.012)   Loss 0.0849 (0.0708)   Prec@1 97.656 (97.664)   Prec@5 100.000 (99.977)   [2019-08-31 00:55:27]
  **Test** Prec@1 91.480 Prec@5 99.720 Error@1 8.520

==>>[2019-08-31 00:57:01] [Epoch=091/100] [Need: 00:25:33] [learning_rate=0.0000] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [091][000/391]   Time 4.685 (4.685)   Data 4.369 (4.369)   Loss 0.1486 (0.1486)   Prec@1 93.750 (93.750)   Prec@5 100.000 (100.000)   [2019-08-31 00:57:06]
  Epoch: [091][200/391]   Time 0.361 (0.405)   Data 0.000 (0.022)   Loss 0.0539 (0.0694)   Prec@1 99.219 (97.788)   Prec@5 100.000 (99.992)   [2019-08-31 00:58:22]
  **Test** Prec@1 91.290 Prec@5 99.690 Error@1 8.710

==>>[2019-08-31 00:59:55] [Epoch=092/100] [Need: 00:22:43] [learning_rate=0.0000] [Best : Accuracy=91.52, Error=8.48]
  Epoch: [092][000/391]   Time 3.862 (3.862)   Data 3.437 (3.437)   Loss 0.0520 (0.0520)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-08-31 00:59:59]
  Epoch: [092][200/391]   Time 0.242 (0.398)   Data 0.000 (0.017)   Loss 0.0688 (0.0656)   Prec@1 97.656 (97.847)   Prec@5 100.000 (99.988)   [2019-08-31 01:01:15]
  **Test** Prec@1 91.530 Prec@5 99.750 Error@1 8.470

==>>[2019-08-31 01:02:48] [Epoch=093/100] [Need: 00:19:53] [learning_rate=0.0000] [Best : Accuracy=91.53, Error=8.47]
  Epoch: [093][000/391]   Time 3.932 (3.932)   Data 3.443 (3.443)   Loss 0.0783 (0.0783)   Prec@1 97.656 (97.656)   Prec@5 99.219 (99.219)   [2019-08-31 01:02:52]
  Epoch: [093][200/391]   Time 0.363 (0.385)   Data 0.000 (0.018)   Loss 0.0605 (0.0673)   Prec@1 96.875 (97.827)   Prec@5 100.000 (99.988)   [2019-08-31 01:04:05]
  **Test** Prec@1 91.590 Prec@5 99.740 Error@1 8.410

==>>[2019-08-31 01:05:31] [Epoch=094/100] [Need: 00:17:02] [learning_rate=0.0000] [Best : Accuracy=91.59, Error=8.41]
  Epoch: [094][000/391]   Time 4.121 (4.121)   Data 3.596 (3.596)   Loss 0.0920 (0.0920)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-08-31 01:05:35]
  Epoch: [094][200/391]   Time 0.318 (0.366)   Data 0.000 (0.018)   Loss 0.0353 (0.0693)   Prec@1 100.000 (97.652)   Prec@5 100.000 (99.992)   [2019-08-31 01:06:45]
  **Test** Prec@1 91.440 Prec@5 99.710 Error@1 8.560

==>>[2019-08-31 01:08:09] [Epoch=095/100] [Need: 00:14:11] [learning_rate=0.0000] [Best : Accuracy=91.59, Error=8.41]
  Epoch: [095][000/391]   Time 4.534 (4.534)   Data 4.183 (4.183)   Loss 0.1074 (0.1074)   Prec@1 98.438 (98.438)   Prec@5 100.000 (100.000)   [2019-08-31 01:08:13]
  Epoch: [095][200/391]   Time 0.460 (0.383)   Data 0.000 (0.022)   Loss 0.1223 (0.0677)   Prec@1 96.875 (97.800)   Prec@5 100.000 (99.992)   [2019-08-31 01:09:26]
  **Test** Prec@1 90.930 Prec@5 99.680 Error@1 9.070

==>>[2019-08-31 01:10:48] [Epoch=096/100] [Need: 00:11:20] [learning_rate=0.0000] [Best : Accuracy=91.59, Error=8.41]
  Epoch: [096][000/391]   Time 4.311 (4.311)   Data 3.661 (3.661)   Loss 0.0636 (0.0636)   Prec@1 99.219 (99.219)   Prec@5 100.000 (100.000)   [2019-08-31 01:10:52]
  Epoch: [096][200/391]   Time 0.400 (0.379)   Data 0.000 (0.018)   Loss 0.0573 (0.0644)   Prec@1 98.438 (97.979)   Prec@5 100.000 (99.996)   [2019-08-31 01:12:04]
  **Test** Prec@1 91.410 Prec@5 99.710 Error@1 8.590

==>>[2019-08-31 01:13:26] [Epoch=097/100] [Need: 00:08:30] [learning_rate=0.0000] [Best : Accuracy=91.59, Error=8.41]
  Epoch: [097][000/391]   Time 4.281 (4.281)   Data 3.762 (3.762)   Loss 0.0524 (0.0524)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-08-31 01:13:30]
  Epoch: [097][200/391]   Time 0.279 (0.376)   Data 0.000 (0.019)   Loss 0.0589 (0.0676)   Prec@1 97.656 (97.804)   Prec@5 100.000 (99.973)   [2019-08-31 01:14:42]
  **Test** Prec@1 91.210 Prec@5 99.740 Error@1 8.790

==>>[2019-08-31 01:16:04] [Epoch=098/100] [Need: 00:05:39] [learning_rate=0.0000] [Best : Accuracy=91.59, Error=8.41]
  Epoch: [098][000/391]   Time 3.045 (3.045)   Data 2.700 (2.700)   Loss 0.0749 (0.0749)   Prec@1 97.656 (97.656)   Prec@5 100.000 (100.000)   [2019-08-31 01:16:07]
  Epoch: [098][200/391]   Time 0.379 (0.335)   Data 0.000 (0.014)   Loss 0.0890 (0.0643)   Prec@1 97.656 (97.967)   Prec@5 100.000 (99.981)   [2019-08-31 01:17:11]
  **Test** Prec@1 91.410 Prec@5 99.700 Error@1 8.590

==>>[2019-08-31 01:18:26] [Epoch=099/100] [Need: 00:02:49] [learning_rate=0.0000] [Best : Accuracy=91.59, Error=8.41]
  Epoch: [099][000/391]   Time 3.468 (3.468)   Data 3.169 (3.169)   Loss 0.0979 (0.0979)   Prec@1 95.312 (95.312)   Prec@5 100.000 (100.000)   [2019-08-31 01:18:29]
  Epoch: [099][200/391]   Time 0.352 (0.299)   Data 0.000 (0.016)   Loss 0.0457 (0.0648)   Prec@1 98.438 (97.889)   Prec@5 100.000 (99.988)   [2019-08-31 01:19:26]
  **Test** Prec@1 91.230 Prec@5 99.710 Error@1 8.770
